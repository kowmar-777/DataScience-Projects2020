{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['language','text']\n",
    "lista=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = {'en':'http://en.wikipedia.org/wiki/Wikipedia',\n",
    "        'fi':'http://fi.wikipedia.org/wiki/Wikipedia',         \n",
    "        'pl1':'https://pl.wikipedia.org/wiki/Podsumowanie_startów_zespołu_March_w_Formule_1',\n",
    "         'pl2':'https://pl.wikipedia.org/wiki/Upiór_w_operze',\n",
    "        'sv':'http://sv.wikipedia.org/wiki/Wikipedia',\n",
    "         'da1':'https://da.wikipedia.org/wiki/VHL_2019-20',\n",
    "         'da':'https://da.wikipedia.org/wiki/Kimbrere',\n",
    "        'de':'http://de.wikipedia.org/wiki/Wikipedia',\n",
    "        'nl':'http://nl.wikipedia.org/wiki/Wikipedia',\n",
    "         'fi1':'https://fi.wikipedia.org/wiki/Pirjo_Honkasalo',\n",
    "        'no':'http://no.wikipedia.org/wiki/Wikipedia', \n",
    "         'nl3':'https://nl.wikipedia.org/wiki/Berlin_Hauptbahnhof',\n",
    "        'da2':'http://da.wikipedia.org/wiki/Wikipedia',\n",
    "         'nl2':'https://nl.wikipedia.org/wiki/Spoorlijn_Amsterdam_-_Haarlem',\n",
    "        'pl':'http://pl.wikipedia.org/wiki/Wikipedia',\n",
    "        'da3':'https://da.wikipedia.org/wiki/Beryllium',         \n",
    "         'fi2':'https://fi.wikipedia.org/wiki/Helsinki',\n",
    "         'nl1':'https://nl.wikipedia.org/wiki/Geschiedenis_van_de_spoorwegen_in_Nederland',\n",
    "         'no1':'https://no.wikipedia.org/wiki/Berlin',\n",
    "         'sv1':'https://sv.wikipedia.org/wiki/Berlin',\n",
    "         'pl3':'https://pl.wikipedia.org/wiki/Berlin'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for element in pages:\n",
    "    lang = element\n",
    "    response = requests.get(pages[element])\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content,'lxml')\n",
    "        paragrs = soup.find_all('p')\n",
    "        \n",
    "        if paragrs:\n",
    "            for pr in paragrs:\n",
    "                tmptext = pr.text\n",
    "                if len(tmptext) > 100:\n",
    "                    \n",
    "                    l=[lang,tmptext]\n",
    "                    lista.append(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lista,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wytnij(text):\n",
    "    return text[:2]\n",
    "df['language'] = df['language'].apply(wytnij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "language      \n",
       "da         140\n",
       "de         159\n",
       "en         148\n",
       "fi         162\n",
       "nl         109\n",
       "no         152\n",
       "pl         107\n",
       "sv         217"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('language').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "def textTokenize(text):\n",
    "    table = word_tokenize(text)\n",
    "    \n",
    "    tab = [w for w in table if not (w in set(punctuation))]\n",
    "    tab = [w for w in tab if w.isalpha()]\n",
    "    \n",
    "    #table = text.split(' ')\n",
    "    return tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_text'] = df['text'].apply(textTokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(tokens):\n",
    "    \n",
    "    tmp = ' '.join(tokens)\n",
    "    tmp = tmp.lower()\n",
    "    \n",
    "    return tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['token_text'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model training\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sklearn.utils.shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['language'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),analyzer='char',use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect',vectorizer),\n",
    "    ('clf',Perceptron()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='char', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=False,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=0.0001, class_weight=None,\n",
       "                            early_stopping=False, eta0=1.0, fit_intercept=True,\n",
       "                            max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                            penalty=None, random_state=0, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581239530988275"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          da       0.88      0.98      0.93        66\n",
      "          de       0.89      1.00      0.94        74\n",
      "          en       0.99      0.99      0.99        85\n",
      "          fi       0.99      0.99      0.99        76\n",
      "          nl       1.00      0.98      0.99        53\n",
      "          no       0.98      0.77      0.86        83\n",
      "          pl       1.00      0.98      0.99        55\n",
      "          sv       0.96      0.99      0.98       105\n",
      "\n",
      "    accuracy                           0.96       597\n",
      "   macro avg       0.96      0.96      0.96       597\n",
      "weighted avg       0.96      0.96      0.96       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='char', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=False,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=0.0001, class_weight=None,\n",
       "                            early_stopping=False, eta0=1.0, fit_intercept=True,\n",
       "                            max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                            penalty=None, random_state=0, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df['clean_text'], df['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype='<U2')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['could you please confirm if swedac is an active customer i was told by satu sairi it was terminated but we are still being charged by exela this may contain confidential privileged information if you are not the intended recipient or have received this in error please notify the sender immediately and destroy this any unauthorized copying disclosure or distribution of the material in this is strictly forbidden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('t.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('langClf.pickle','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.predict(['Dear user, Error description: The invoice e-mail message you created and sent could not be completed.Please re-send the corrected email message with all invoice attachments; the previously sent email has not reached its receiver.We have registered this error notification. Please use the subject field of this email message unaltered when sending email related to this error message.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d773658e09fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dear user, Error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.predict(['Dear user, Error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
